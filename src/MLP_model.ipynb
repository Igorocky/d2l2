{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/text-1.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read().lower().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2int = {c:(i+1) for i,c in enumerate(chars)}\n",
    "# sot = '>'\n",
    "# assert sot not in char2int\n",
    "# char2int[sot] = 0\n",
    "int2char = {i:c for c,i in char2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctxLen = 20\n",
    "def getSamples():\n",
    "    random.seed(123)\n",
    "    samplNum = 100\n",
    "    idxs = random.sample(range(0,len(text)-ctxLen), samplNum)\n",
    "    X,Y = [],[]\n",
    "    for i in idxs:\n",
    "        X.append(text[i:i+ctxLen])\n",
    "        Y.append(text[i+1:i+ctxLen+1])\n",
    "    trSamplPct = 0.8\n",
    "    i1 = int(trSamplPct*len(X))\n",
    "    i2 = int((i1 + len(X)) / 2)\n",
    "    Xtr,Ytr = X[:i1], Y[:i1]\n",
    "    Xval,Yval = X[i1:i2], Y[i1:i2]\n",
    "    Xtest,Ytest = X[i2:], Y[i2:]\n",
    "    return (\n",
    "        Xtr,Ytr,\n",
    "        Xval,Yval,\n",
    "        Xtest,Ytest,\n",
    "    )\n",
    "Xtr,Ytr, Xval,Yval, Xtest,Ytest = getSamples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self,fanIn,fanOut,activation):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(fanIn,fanOut)\n",
    "        self.act = activation\n",
    "    def forward(self,x):\n",
    "        y = self.lin(x)\n",
    "        if self.act != None:\n",
    "            y = self.act(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpModel(nn.Module):\n",
    "    def __init__(self,fanIn,sizes):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(*[\n",
    "            Linear(\n",
    "                fanIn = fanIn if i == 0 else sizes[i-1], \n",
    "                fanOut = sizes[i], \n",
    "                activation = None if i == len(sizes)-1 else torch.nn.functional.leaky_relu\n",
    "            ) for i in range(len(sizes))\n",
    "        ])\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2016,  0.0750, -0.2085,  ...,  0.0093, -0.1055,  0.1632],\n",
       "         [ 0.1994, -0.1762, -0.0265,  ..., -0.0241, -0.0112,  0.0294],\n",
       "         [ 0.0014, -0.1645, -0.1499,  ...,  0.1917,  0.0826, -0.2090],\n",
       "         ...,\n",
       "         [ 0.1110,  0.2007, -0.0549,  ..., -0.0352, -0.1630,  0.2104],\n",
       "         [-0.1522,  0.1235,  0.1966,  ...,  0.0996,  0.1539,  0.1738],\n",
       "         [ 0.1937,  0.1628, -0.0520,  ...,  0.1617, -0.2083,  0.0608]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1752,  0.0749, -0.1147,  0.0146,  0.1331,  0.0701, -0.0721, -0.0218,\n",
       "         -0.1663,  0.1065, -0.1549,  0.0618,  0.1168, -0.0312,  0.2109, -0.2118,\n",
       "         -0.0812,  0.0775,  0.1026,  0.1929, -0.2138, -0.0749,  0.0709,  0.1014,\n",
       "          0.0798, -0.1150, -0.2043, -0.0182,  0.0509, -0.1481, -0.0764,  0.1729,\n",
       "         -0.1195,  0.0867,  0.1828,  0.0940, -0.1486, -0.1374,  0.0671, -0.1904,\n",
       "          0.0755, -0.0583, -0.1308, -0.2054,  0.0737,  0.0764, -0.1411,  0.0545,\n",
       "         -0.1938, -0.1559, -0.2006,  0.0677, -0.0788,  0.0561,  0.0685, -0.0831,\n",
       "          0.0045,  0.2209,  0.2018, -0.1418,  0.1768,  0.1965,  0.2127,  0.0171,\n",
       "         -0.0322, -0.1300,  0.0399, -0.1200,  0.1800,  0.0179, -0.2086, -0.2036,\n",
       "          0.0231,  0.0922, -0.0812, -0.0383,  0.1332,  0.1281,  0.1169,  0.0969,\n",
       "         -0.2072, -0.1798,  0.1457,  0.1414, -0.1405, -0.1059, -0.0390, -0.0267,\n",
       "          0.0652, -0.1541, -0.1960,  0.1331, -0.1849, -0.0563,  0.0505, -0.0198,\n",
       "          0.0138,  0.1199,  0.1668, -0.1650], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0650,  0.0948,  0.0713,  ...,  0.0929,  0.0974,  0.0936],\n",
       "         [ 0.0500, -0.0817, -0.0549,  ..., -0.0884, -0.0023,  0.0624],\n",
       "         [ 0.0531, -0.0513, -0.0237,  ...,  0.0986,  0.0704, -0.0556],\n",
       "         ...,\n",
       "         [ 0.0925,  0.0496, -0.0657,  ...,  0.0421, -0.0823, -0.0647],\n",
       "         [-0.0894,  0.0325, -0.0455,  ...,  0.0589, -0.0283,  0.0637],\n",
       "         [ 0.0399,  0.0928, -0.0825,  ..., -0.0797,  0.0103,  0.0906]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0720, -0.0431,  0.0682, -0.0547,  0.0193, -0.0546,  0.0538,  0.0604,\n",
       "         -0.0033, -0.0145,  0.0775, -0.0353,  0.0412, -0.0982, -0.0695, -0.0156,\n",
       "         -0.0889, -0.0858, -0.0412, -0.0475], requires_grad=True)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MlpModel(fanIn=ctxLen, sizes=[100,ctxLen])\n",
    "[p for p in model.parameters()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
