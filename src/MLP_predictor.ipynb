{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import inspect\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/text-1.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read().lower().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numOfTokens=74\n"
     ]
    }
   ],
   "source": [
    "char2int = {c:i for i,c in enumerate(chars)}\n",
    "# sot = '>'\n",
    "# assert sot not in char2int\n",
    "# char2int[sot] = 0\n",
    "int2char = {i:c for c,i in char2int.items()}\n",
    "numOfTokens = len(char2int)\n",
    "print(f'{numOfTokens=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctxLen = 3\n",
    "def getSamples():\n",
    "    random.seed(123)\n",
    "    # def c2i(char):\n",
    "    #     return char2int[char]\n",
    "    samplNum = 100\n",
    "    idxs = random.sample(range(0,len(text)-ctxLen), samplNum)\n",
    "    textInt = [char2int[ch] for ch in text]\n",
    "    X,Y = [],[]\n",
    "    for i in idxs:\n",
    "        X.append(textInt[i:i+ctxLen])\n",
    "        Y.append(textInt[i+1:i+ctxLen+1])\n",
    "    trSamplPct = 0.8\n",
    "    i1 = int(trSamplPct*len(X))\n",
    "    i2 = int((i1 + len(X)) / 2)\n",
    "    Xtr,Ytr = torch.tensor(X[:i1]), torch.tensor(Y[:i1])\n",
    "    Xval,Yval = torch.tensor(X[i1:i2]), torch.tensor(Y[i1:i2])\n",
    "    Xtest,Ytest = torch.tensor(X[i2:]), torch.tensor(Y[i2:])\n",
    "    return (\n",
    "        Xtr,Ytr,\n",
    "        Xval,Yval,\n",
    "        Xtest,Ytest,\n",
    "    )\n",
    "Xtr,Ytr, Xval,Yval, Xtest,Ytest = getSamples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpPredictor(nn.Module):\n",
    "    def __init__(self,numOfTokens,ctxLen,embSize):\n",
    "        super().__init__()\n",
    "        self.ctxLen = ctxLen\n",
    "        self.embSize = embSize\n",
    "        self.emb = nn.Embedding(numOfTokens,embSize)\n",
    "        hidDim = 100\n",
    "        self.lin1 = nn.Linear(ctxLen*embSize,hidDim)\n",
    "        self.lin2 = nn.Linear(hidDim,numOfTokens)\n",
    "    def forward(self,x):\n",
    "        x = self.emb(x).view(-1,self.ctxLen*self.embSize)\n",
    "        x = self.lin1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.lin2(x)\n",
    "        x = F.softmax(x,-1)\n",
    "        return x\n",
    "    def generate(self,ctx,resLen):\n",
    "        if len(ctx) < self.ctxLen:\n",
    "            ctx = ' '*(ctxLen-len(ctx)) + ctx\n",
    "        elif len(ctx) > self.ctxLen:\n",
    "            ctx = ctx[-ctxLen:]\n",
    "        res = []\n",
    "        with torch.no_grad():\n",
    "            while len(res) < resLen:\n",
    "                x = torch.tensor([char2int[ch] for ch in ctx]).unsqueeze(0)\n",
    "                probs = self(x)[0]\n",
    "                nextToken = torch.multinomial(probs, 1)\n",
    "                nextChar = int2char[nextToken[0].item()]\n",
    "                res.append(nextChar)\n",
    "                ctx = ctx[1:] + nextChar\n",
    "        return ''.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print2dEmb(embLayer):\n",
    "    W = embLayer.weight\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.scatter(W[:,0].data,W[:,1].data,s=200)\n",
    "    for i in range(W.shape[0]):\n",
    "        plt.text(W[i,0].item(), W[i,1].item(), int2char[i], ha=\"center\", va=\"center\", color='white')\n",
    "    plt.grid('minor')\n",
    "\n",
    "def showParamsStats(model, layerNameFilter=None):\n",
    "    plt.figure(figsize=(20,4))\n",
    "    legends = []\n",
    "    for pName, pValue in model.named_parameters():\n",
    "        if layerNameFilter == None or layerNameFilter.match(pName):\n",
    "            print(f'layer \\'{pName}\\'[{pValue.nelement()}] mean:{pValue.mean()}, std:{pValue.std()},')\n",
    "            hy,hx = torch.histogram(pValue, density=True)\n",
    "            plt.plot(hx[:-1].detach(),hy.detach(),)\n",
    "            legends.append(pName)\n",
    "    plt.legend(legends);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MlpPredictor(numOfTokens=numOfTokens,ctxLen=ctxLen,embSize=2)\n",
    "# numOfParams = sum(p.nelement() for p in model.parameters())\n",
    "# print(f'{numOfParams=}')\n",
    "# [(pName,pValue.shape) for pName,pValue in model.named_parameters()]\n",
    "# showParamsStats(model,layerNameFilter=re.compile('^lin.*weight$'))\n",
    "# print2dEmb(model.emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mâ„¢ wt;8)/h'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate('',10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
